import os
import json
from typing import List, Dict, Any

OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')


def python_test_template(func):
    name = func['name']
    args = func['args']
    # produce simple unit test skeleton
    params = ', '.join(['None' for _ in args])
    if params:
        call = f"{name}({params})"
    else:
        call = f"{name}()"
    return f"def test_{name}_basic():\n    # TODO: replace with meaningful assertions\n    result = {call}\n    assert result is not None\n"


def generate_tests_for_project(language: str, files, analysis: Dict[str,Any], options: Dict[str,Any]):
    """Return a mapping of test filenames -> test content."""
    out = {}
    if language.lower() == 'python':
        tests = []
        for f in analysis.get('functions', []):
            tests.append(python_test_template(f))
        # edge tests
        edges = analysis.get('edges', [])
        if edges:
            edge_content = '# Edge tests suggestions:\n'
            for e in edges:
                edge_content += f'# - {e}\n'
            tests.append(edge_content)
        out['tests/test_autogen.py'] = '\n\n'.join(tests) or '# No tests generated\n'
        # Optionally call OpenAI to improve coverage
        if options.get('use_llm') and OPENAI_API_KEY:
            improved = call_openai_for_tests(language, files, analysis)
            if improved:
                out['tests/test_autogen_llm.py'] = improved
    elif language.lower() in ('javascript','js'):
        # Generate a Jest test file skeleton
        content = "// Auto-generated Jest tests\n"
        for f in analysis.get('functions', []):
            fname = f['name']
            content += f"test('{fname} basic', () => {{\n  // TODO: call and assert\n}})\n\n"
        out['tests/autogen.test.js'] = content
    elif language.lower() == 'java':
        # JUnit skeleton
        content = "// Autogenerated JUnit tests (put into src/test/java)\n"
        out['tests/AutogenTest.java'] = content
    else:
        raise ValueError('Unsupported language')
    return out


def call_openai_for_tests(language, files, analysis):
    # This is a thin wrapper showing how to call OpenAI for richer test generation.
    # The user must set OPENAI_API_KEY in env. This function may be expanded.
    try:
        import openai
        openai.api_key = OPENAI_API_KEY
        prompt = f"Generate pytest tests for the following analysis: {json.dumps(analysis)}\nFiles:\n"
        for f in files:
            prompt += f"--- {f.path} ---\n{f.content}\n"
        prompt += "\nProvide only a plain .py test file content."
        resp = openai.ChatCompletion.create(
            model='gpt-4o-mini',
            messages=[{'role':'user','content':prompt}],
            temperature=0.0,
            max_tokens=1200
        )
        text = resp['choices'][0]['message']['content']
        return text
    except Exception as e:
        print('OpenAI call failed:', e)
        return None

# ----------------------------- runner.py -----------------------------------
# Save as runner.py
import os
import subprocess
import tempfile
import shutil
from typing import List, Dict, Any


def write_files_to_dir(files: List[Dict[str,str]], base_dir: str):
    for f in files:
        path = os.path.join(base_dir, f['path'])
        os.makedirs(os.path.dirname(path), exist_ok=True)
        with open(path, 'w', encoding='utf-8') as fh:
            fh.write(f['content'])


def run_tests_in_sandbox(language: str, files: List[Dict[str,str]], test_files: List[Dict[str,str]]):
    tmp = tempfile.mkdtemp(prefix='tcgb_')
    try:
        # write project files
        write_files_to_dir(files, tmp)
        write_files_to_dir(test_files, tmp)
        if language.lower() == 'python':
            # run pytest with coverage
            cmd = ['coverage', 'run', '-m', 'pytest', '-q']
            proc = subprocess.run(cmd, cwd=tmp, capture_output=True, text=True)
            stdout = proc.stdout
            stderr = proc.stderr
            # generate coverage report
            cov_cmd = ['coverage', 'json', '-o', 'coverage.json']
            subprocess.run(cov_cmd, cwd=tmp)
            cov_json = None
            cov_path = os.path.join(tmp, 'coverage.json')
            if os.path.exists(cov_path):
                with open(cov_path, 'r') as fh:
                    cov_json = fh.read()
            return {'returncode': proc.returncode, 'stdout': stdout, 'stderr': stderr, 'coverage': cov_json}
        elif language.lower() in ('javascript','js'):
            # expects node and jest installed in environment
            # write package.json if not present
            if not os.path.exists(os.path.join(tmp,'package.json')):
                pj = {'name':'autogen','version':'1.0.0','scripts':{'test':'jest --json --outputFile=jest_output.json'}}
                with open(os.path.join(tmp,'package.json'),'w') as fh:
                    import json
                    fh.write(json.dumps(pj))
            proc = subprocess.run(['npm','install','--no-audit','--no-fund'], cwd=tmp, capture_output=True, text=True)
            proc2 = subprocess.run(['npm','test'], cwd=tmp, capture_output=True, text=True)
            # read jest_output.json if produced
            jest_out = None
            jest_path = os.path.join(tmp,'jest_output.json')
            if os.path.exists(jest_path):
                with open(jest_path,'r') as fh:
                    jest_out = fh.read()
            return {'returncode': proc2.returncode, 'stdout': proc2.stdout, 'stderr': proc2.stderr, 'jest': jest_out}
        elif language.lower() == 'java':
            # naive: assume tests compiled with junit and run with mvn (user should provide pom.xml)
            mvn_proc = subprocess.run(['mvn','-v'], cwd=tmp, capture_output=True, text=True)
            run_proc = subprocess.run(['mvn','test'], cwd=tmp, capture_output=True, text=True)
            return {'returncode': run_proc.returncode, 'stdout': run_proc.stdout, 'stderr': run_proc.stderr}
        else:
            raise ValueError('Unsupported language')
    finally:
        shutil.rmtree(tmp)
